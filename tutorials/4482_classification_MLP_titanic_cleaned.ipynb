{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewpecsok/4482_fall_2022/blob/main/tutorials/4482_classification_MLP_titanic_cleaned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWVgdVutJP98"
      },
      "source": [
        "Welcome to the MLP classification notebook. In this notebook we will be exploring two new items. \n",
        "\n",
        "* The first will be learning how to use the MultiLayerPerceptron Algorithm. In the case that we start introducing hidden layers one would call this \"Deep Learning\" and \"Deep Neural Network\" which is an extremely powerful modeling technique. \n",
        "\n",
        "* The second concept which is extremely relevant for DNN is the selection of and tuning of hyperparameters. This selection can be computationally expensive and time consuming. For this we introduce sklearn's gridsearchcv to help us search/explore the parameter space without having to code this manually. \n",
        "\n",
        "* The notebook will begin by simply creating MLP models with various numbers of layers and a variety of neurons in each layer with the models becoming more computationally expensive and complex. Pay attention to the metrics to see if this complexity has actually improved our predictions. DNNs are notorious for overfitting data because they can become arbitrarily complex. \n",
        "\n",
        "* After you have grasped the primary concept of the DNN we will introduce other hyperparameters that are often tuned to improve the model, and finally we will introduce gridsearchcv to bring this code complexity back down to a reasonable effort. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjKEFgC7Ycm_"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbDv78ea7uk-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix,\\\n",
        " recall_score, precision_score, f1_score, accuracy_score, make_scorer,\\\n",
        "  precision_recall_fscore_support\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqyRu9C4YfJy"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL9otp_39m7r"
      },
      "source": [
        "titanic_cleaned = pd.read_csv('https://raw.githubusercontent.com/matthewpecsok/4482_fall_2022/main/data/titanic_cleaned.csv').drop('Cabin', axis=1) # drop cabin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifk5nluWDuf7"
      },
      "source": [
        "titanic_cleaned.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKkWpTpV4jtk"
      },
      "source": [
        "titanic_cleaned['Pclass'] = titanic_cleaned.Pclass.astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrKnruWR4kJ4"
      },
      "source": [
        "titanic_cleaned.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPWZ7XI44Dqw"
      },
      "source": [
        "y = titanic_cleaned.pop('Survived')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuEa_lDSW1-_"
      },
      "source": [
        "X = pd.get_dummies(titanic_cleaned)\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQa9YZviloKQ"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9iyfH2CYgR8"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIdP_L-ctI8n"
      },
      "source": [
        "# Changing the number of hidden layers on the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsIzyTF9YhYj"
      },
      "source": [
        "### Model 1 (no hidden layers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5YIii099yvB"
      },
      "source": [
        "model_1 = MLPClassifier(random_state=2021,hidden_layer_sizes=()).fit(X,y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqxcXGK3kLD_"
      },
      "source": [
        "model_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e223qTSskUe_"
      },
      "source": [
        "model_1.n_layers_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7eAMdNnl7Yt"
      },
      "source": [
        "model_1.hidden_layer_sizes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XakaR5Y0n1Mg"
      },
      "source": [
        "model_1.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm7R1ErRn3zQ"
      },
      "source": [
        "len(model_1.coefs_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_I61jLWoBX9"
      },
      "source": [
        "model_1.coefs_[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e15MbIq5pAFU"
      },
      "source": [
        "model_1.coefs_[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDviTtBk808N"
      },
      "source": [
        "model_1_cv_results = pd.DataFrame(cross_validate(model_1,\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "\n",
        "model_1_cv_results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4nA2_FSYv_j"
      },
      "source": [
        "### Model 2 (1 hidden layer with 50 neurons)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K96ZGMf2CLbJ"
      },
      "source": [
        "# why do we fit here? without fitting we have no layers\n",
        "model_2 = MLPClassifier(random_state=2021,hidden_layer_sizes=(50,)).fit(X,y)\n",
        "print(\"hidden layers sizes\",model_2.hidden_layer_sizes)\n",
        "print(\"n_layers_\",model_2.n_layers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy48EKnXBoIr"
      },
      "source": [
        "model_2_cv_results = pd.DataFrame(cross_validate(model_2,\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "\n",
        "model_2_cv_results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUibNVruKyYZ"
      },
      "source": [
        "### Model 3 (2 hidden layers, the first has 15 neurons and the second has 10 neurons)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqt6FfL8H93J"
      },
      "source": [
        "# why do we fit here? without fitting we have no layers\n",
        "model_3 = MLPClassifier(random_state=2021,hidden_layer_sizes=(15,10)).fit(X,y)\n",
        "print(\"hidden layers sizes\",model_3.hidden_layer_sizes)\n",
        "print(\"n_layers_\",model_3.n_layers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwrUqQn-IQ-t"
      },
      "source": [
        "model_3_cv_results = pd.DataFrame(cross_validate(model_3,\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "\n",
        "model_3_cv_results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gSo4c_syV9b"
      },
      "source": [
        "### Model 3 (3 hidden layers, the first has 50 neurons , the second has 25 neurons, the third has 10 neurons)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5C0UNi-PFpI"
      },
      "source": [
        "# why do we fit here? without fitting we have no layers\n",
        "model_4 = MLPClassifier(random_state=2021,hidden_layer_sizes=(50,25,10)).fit(X,y)\n",
        "print(\"hidden layers sizes\",model_4.hidden_layer_sizes)\n",
        "print(\"n_layers_\",model_4.n_layers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZfbMW36PGTX"
      },
      "source": [
        "model_4_cv_results = pd.DataFrame(cross_validate(model_4,\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "\n",
        "model_4_cv_results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eml2qocVydN8"
      },
      "source": [
        "### Model 5 (4 hidden layers, the first has 100 neurons , the second has 50 neurons, the third has 25 neurons and the fourth has 10 neurons)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rIiRM6hQEJr"
      },
      "source": [
        "# why do we fit here? without fitting we have no layers\n",
        "model_5 = MLPClassifier(random_state=2021,hidden_layer_sizes=(100,50,25,10)).fit(X,y)\n",
        "print(\"hidden layers sizes\",model_5.hidden_layer_sizes)\n",
        "print(\"n_layers_\",model_5.n_layers_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j9IP2eEQD9W"
      },
      "source": [
        "model_5_cv_results = pd.DataFrame(cross_validate(model_5,\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "\n",
        "model_5_cv_results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-O7e8WsyruO"
      },
      "source": [
        "### Model 6 (5 hidden layers, the first has 100 neurons , the second has 50 neurons, the third has 25 neurons , the fourth has 25 neurons , the fifth has 10 neurons)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9QxFiMoTDWm"
      },
      "source": [
        "model_6_cv_results = pd.DataFrame(cross_validate(MLPClassifier(random_state=2021,hidden_layer_sizes=(100,50,25,25,10)),\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "\n",
        "model_6_cv_results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRToaqHdyzr-"
      },
      "source": [
        "### Model 7 (3 hidden layers each with 500 neurons)\n",
        "\n",
        "notice how much longer this model took to train compared to the others!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwMOloEMwcdu"
      },
      "source": [
        "model_7_cv_results = pd.DataFrame(cross_validate(MLPClassifier(random_state=2021,hidden_layer_sizes=(500,500,500)),\n",
        "               X,\n",
        "               y,\n",
        "               cv = 3,\n",
        "               return_train_score=True,\n",
        "               scoring=['accuracy','recall','precision','f1']))\n",
        "\n",
        "model_7_cv_results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHuOl_DVvNQI"
      },
      "source": [
        "model_1_cv_results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfghrQu6vT_h"
      },
      "source": [
        "model_2_cv_results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9teCt2RvVtn"
      },
      "source": [
        "model_3_cv_results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSQQXq8tvVer"
      },
      "source": [
        "model_4_cv_results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbzOddXEvVEF"
      },
      "source": [
        "model_5_cv_results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSTAK9nYvUZC"
      },
      "source": [
        "model_6_cv_results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfxIu3qV2lMx"
      },
      "source": [
        "model_7_cv_results.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7H7O32mvqUA"
      },
      "source": [
        "Analyzing the results as shown above notice that the performance of the models is not always increasing even though the complexity is increasing. The increased complexity does seem to increase the fit time though which is expected. A more complex model will take longer to train. So there is a trade off between quality of the model and complexity of the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGWHzTfuwAG6"
      },
      "source": [
        "In addition, notice how much code we had to write just to get these results? And if you were starting to feel like the code is redundant for each section you are correct! Notice with a simple function how we can do exactly the same thing much easier as shown below. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'hidden_layer_sizes':[(),\n",
        "                                    (5),\n",
        "                                    (10,),\n",
        "                                    (20,),\n",
        "                                    (30,),\n",
        "                                    (40,),\n",
        "                                    (50,),\n",
        "                                    (50,),\n",
        "                                    (60,),\n",
        "                                    (70,),\n",
        "                                    (80,),\n",
        "                                    (90,),\n",
        "                                    (100,),\n",
        "\n",
        "\n",
        "                                    (5,5),\n",
        "                                    (10,10),\n",
        "                                    (20,20),\n",
        "                                    (30,30),\n",
        "                                    (40,40),\n",
        "                                    (50,50),\n",
        "                                    (60,60),\n",
        "                                    (70,70),\n",
        "                                    (80,80),\n",
        "                                    (90,90),\n",
        "                                    (100,100),\n",
        "                                    ],\n",
        "              }\n",
        "mlp = MLPClassifier(random_state=2021)\n",
        "clf = GridSearchCV(mlp, parameters,scoring='accuracy',return_train_score=True,cv=3)\n",
        "clf.fit(X, y)"
      ],
      "metadata": {
        "id": "lQSl9kIFTCAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_df = pd.DataFrame(clf.cv_results_)\n",
        "grid_search_df.sort_values('rank_test_score')[['rank_test_score','param_hidden_layer_sizes','mean_test_score','mean_train_score']]"
      ],
      "metadata": {
        "id": "bJQDd2NHTegb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61yN_Un_3sW8"
      },
      "source": [
        "# Learning Rate Hyperparameter\n",
        "\n",
        "Before this we were simply looking at the number of hidden layers and the quantity of neurons in this hidden layers to improve our model. Another common tuning hyperparameter is learning rate. This is the rate at which the weights are adjusted and has two primary benefits. The first is that a learning weight can impact the models ability to learn more quickly or slowly and second that it can help the model stay out of local minima and hopefully find the globbal minumum when reducing loss as it is getting tuned.\n",
        "\n",
        "Let's do a quick exploration of this and its impact on training using a simple example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_odr0cJMLmr"
      },
      "source": [
        "after the gridsearch explores all the model combinations it selects the best model set of hyperparameters to be used. Once this model is trained it may result in an improvement over our previous efforts. Notice that I have not explored EVERY possible model we created previously and have instead opted to explore a variety of other hyperparameters to see if it's possible to achieve a better prediction than we achieved previously in the notebook. \n",
        "\n",
        "The point to take away from this is that\n",
        "1. There are an infinite number of hyperparameter combinations\n",
        "1. It's impossible to explore them all by hand\n",
        "1. For each combination a model must be trained\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'hidden_layer_sizes':[(),\n",
        "                                    (5),\n",
        "                                    (10,),\n",
        "                                    (20,),\n",
        "                                    (30,),\n",
        "                                    (40,),\n",
        "                                    (50,),\n",
        "                                    (50,),\n",
        "                                    (60,),\n",
        "                                    (70,),\n",
        "                                    (80,),\n",
        "                                    (90,),\n",
        "                                    (100,),\n",
        "\n",
        "\n",
        "                                    (5,5),\n",
        "                                    (10,10),\n",
        "                                    (20,20),\n",
        "                                    (30,30),\n",
        "                                    (40,40),\n",
        "                                    (50,50),\n",
        "                                    (60,60),\n",
        "                                    (70,70),\n",
        "                                    (80,80),\n",
        "                                    (90,90),\n",
        "                                    (100,100),\n",
        "                                    ],\n",
        "              'learning_rate_init':[0.1,0.01,0.001],\n",
        "              'activation':['identity', 'logistic', 'tanh', 'relu'],\n",
        "              'alpha':[0.0001,0.001,0.01,0.1]\n",
        "              }\n",
        "mlp = MLPClassifier(random_state=2021)\n",
        "clf = GridSearchCV(mlp, parameters,scoring='accuracy',return_train_score=True,cv=3)\n",
        "clf.fit(X, y)"
      ],
      "metadata": {
        "id": "y-Qr_0-ibJc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_df = pd.DataFrame(clf.cv_results_)\n",
        "grid_search_df = round(grid_search_df,4)\n",
        "grid_search_df = grid_search_df.sort_values('rank_test_score')[['rank_test_score','params','mean_test_score','mean_train_score']]\n",
        "from google.colab import data_table\n",
        "data_table.DataTable(grid_search_df)\n"
      ],
      "metadata": {
        "id": "eY1b_1pTbuFF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}